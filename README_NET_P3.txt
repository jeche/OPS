Nachos Networking

All changes that were made in relation to this project occurred either in userprog, filesys, or threads.

For setting up the network paging, changes were made to create a thread on the server and allocate a mailbox on the server (the client's machine number) for each client that would handle all interactions with that client.  Note that we have a bitmap keeping track of which mailboxes are in use so that if the clients try to do any sort of network communication between each other they will not use the ones previously designated for paging or migrating.  The thread on the server listens for requests from its specified client(the client is specified when it is originally forked off). It utilizes the mailHdr.length to determine what kind of request the client is making. One of the requests clients can make related to paging is reading a page (mailHdr.length == 1), the page being requested is denoted by an integer in the ackHdr (a header specifically designed for us to easily pass more information through mail) of the request. The server then accesses its synchDisk to read the specified page out into a buffer and replies to the client with a piece of mail that contains the page requested in the data. The next request possible is writing a page back, when doing so the length of the mail is denoted to be the pageSize (128) due to the only data in the mail being all 128 characters for the dirty page, the server processes the request by accessing its synchDisk and writing the page to the disk. It then replies back to the client to let the client know it has finished. Another request related to paging is that clients may also request a page be allocated to them as well as release a page from the server. The server has a bitmap which keeps track of the pages currently free. When the client sends a request for a page to either be cleared or allocated the server updates the bitmap accordingly and then replies to the client with confirmation, or the number of the allocated page. Clients always make and receive replies for requests related to remote paging locally (to the client) on mailbox 0.  

For the migration the mailbox that has the same number as the server's machine number is used to communicate with clients. The clients use their own mailbox 1 to communicate back to the server. The clients all have an additional thread that listens for the server attempting to tell it that something related to migration should happen. Another integer value located in the ackHdr denotes what kind of communication related to migration the message received is. On a migrate the server sends a message to the victim (the loser of a process) telling it to grab a user thread (migrateFlag == 0). The victim-client grabs a user thread by stealing it off the readyToRun list in the scheduler. The vicitm it selects must be a userthread, not have been previously migrated, cannot have forked any kids into existence, and cannot be the first process started up on the machine(the -x process). If there are no processes that are on the readyList that fit these criteria, then it returns a NULL which is dealt with in the migrationHandler where an error message is sent back to the server. If this is not the case, it then creates the migckpt file to write out all of the victim user thread's information to the file. After doing so we destroy the addrspace of the stolen thread and delete it. We then perform a Murder on the victim user thread, Murder is a new function that can be performed on a thread which tells it to destroy itself. The victim client then replies to the server allowing the server to notify immigrant acceptor client that it may now recreate the immigrant(migrateFlag == 1). The immigrant is reinstantiated as a new process from a checkpoint on the immigrant acceptor machine.  Note that also when a process is migrated the server instantiates a new ForeignThreadNode which tracks the pid of the processs on the original machine, the machine number of the original machine, the pid of the process on new machine, the machine number of the new machine, and the pid of the parent process on the original machine.  These nodes are later used for exitting and joining.

For network exits the server thread for each client and the migration thread on each client are stolen and hacked away at in order to allow for easy communication. When a process exits, if it was a process that has been migrated from another machine, it sends its exit value up to the server (to the mailbox/thread that listens for disk requests). The server then finds out where that process originated from using the foreignThreadNode linked list and sends a notification to the appropriate client via the migration handling thread/mailbox on that client. On a receive of an exit that client then V()'s on the appropriate semaphore denoting a child's death and places the exit value which has been passed along throughout in it's appropriate spot to allow for the parent to get what it needs when it needs it.

For ease we decided to never allow the clients to migrate threads that are currently parents nor allow for a process to migrated more than once.

For automatic load balancing, we have gerryrigged it into our current timeouthandler and our pagefaults, in the server and client respectively. From the point of view of the client, the system has a value numReadyProcs that is the number of processes on the readyList at any time. It is updated in the scheduler anytime a thread is added or removed from the readyList(ReadyToRun and FindNextToRun). Whenever a user process pagefaults, it sends whatever the current value of numReadyProcs is to the server in the migrateFlag field in the AckHeader. From this point on the server handles the rest of automatic load balancing. The server has a float array, clientLoad, with a spot for each individual client's load(Max 10 clients). As the server handles readRequests from clients, it sums the value at clientLoad[client] and the recieved value by weighting the current value and new recieved value. Currently the equation is clientLoad[client] = .8 * clientLoad[client] + .2 * currentClientLoad. For the automatic load balancing aspect, inside the current timeouthandler it iterates through the clientLoad array to see if there is an imbalance among the active clients. Currently it finds the max and min load among the clients and if the difference of the two is greater than 4, it will fork off a thread to do a migration. After the check for an imbalance, it then goes and multiplies all active clientLoad values by .8. This is done for a variety of reasons. First, the main issue with passing the load values through the page fault handling system is if there are no running user threads on a system, it will still have it's load value on the server since it is skewed toward history rather than current. This way, if a machine never pagefaults, eventually the load value will be the minimum load so it will have processes migrated to it. Another reason why this is done is if network reliability is not set to 1, because timeouts on packets sent will occur frequently, it acts as a natural deterant to the system automatically doing a migration that would prevent other machines from sending and recieving page fault message, optimizing overall system performance. Another aspect of automatic load balancing ties into the restrictions as to who can and cannot be migrated. Since it is likely that a system may become composed entirely of processes that cannot be migrated, if we send a request for a thread and the machine cannot give one up, it sends back an error case and the server immediately stops trying to migrate a process that timeout round.

Current Issues:  Note for that more robust tests like VM Torture after several migrates occasionally there is an Illegal Instruction Exception or Address Error Exception.  This is a problem that has been prevalent throughout the semester ever since we started working with page faulting.