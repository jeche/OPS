Nachos Networking

All changes that were made in relation to this project occurred either in userprog, filesys, or threads.

For setting up the network paging, changes were made to create a thread and allocate a mailbox (the client's machine number) for each client on the server that would handle all interactions with that client. The thread on the server would listen for requests from its specified client. It utilizes the mailHdr.length to determine what kind of request the client is making. The requests clients can make related to paging include reading a page (mailHdr.length == 1), the page being requested is denoted by an integer in the ackHdr (a header specifically designed for us to easily pass more information through mail) of the request. The server then accesses its synchDisk to read the specified page out into a buffer and replies to the client with the a piece of mail that contains the page requested in the data. The next request possible is writing a page back, when doing so the length of the mail is denoted to be the pageSize (128) due to the only data in the mail being all 128 characters for the dirty page, the server processes the request by accessing its synchDisk and writing the page to the disk. It then replies back to the client to let the client know it has finished. Another request related to paging is that clients may also request a page be allocated to them as well as release a page from the server. The server has a bitmap which keeps track of the pages currently free. When the client sends a request for a page to either be cleared or allocated the server updates the bitmap accordingly and then replies to the client with confirmation, or the number of the allocated page. Clients always make and receive replies for requests related to remote paging locally (to the client) on mailbox 0.

For the migration the mailbox that has the same number as the server's machine number is used to communicate with clients. The clients use their own mailbox 1 to communicate back to the server. The clients all have an additional thread that listens for the server attempting to tell it that something related to migration should happen. Another integer value located in the ackHdr denotes what kind of communication related to migration the message received is. On a migrate the server sends a message to the victim (the loser of a process) telling it to grab a user thread (migrateFlag == 0). The victim-client grabs a user thread by stealing it off the readyToRun list in the scheduler. The vicitm it selects must be a userthread, not have been previously migrated, cannot have forked any kids into existence, and cannot be the first process started up on the machine(the -x process). If there are no processes that are on the readyList that fit these criteria, then it returns a NULL which is dealt with in the migrationHandler where an error message is sent back to the server. It then creates the migckpt file to write out all of the victim user thread's information to the file. After doing so we destroy the addrspace of the stolen thread and delete it. We then perform a Murder on the victim user thread which tells it to destroy itself. The victim client then replies to the server allowing the server to notify immigrant acceptor client that it may now recreate the immigrant(migrateFlag == 1). The immigrant is reinstantiated as a new process from a checkpoint on the immigrant acceptor machine.

For network exits the server thread for each client and the migration thread on each client are hijacked and hacked away at in order to allow for easy communication. When a process exits, if it was a process that has been migrated, it sends its exit value up to the server (to the mailbox/thread that listens for disk requests). The server than finds out where that process originated from and sends a notification to the appropriate client via the migration handling thread/mailbox on that client. On a receive of an exit that client then V()'s on the appropriate semaphore denoting a child's death and places the exit value which has been passed along throughout in it's appropriate spot to allow for the parent to get what it needs when it needs it.

For ease we decided to never allow the clients to migrate threads that are currently parents.

For automatic load balancing, we have gerryrigged it into our current timeouthandler and our pagefaults, in the server and client respectively. From the point of view of the client, the system has a value numReadyProcs that is the number of processes on the readyList at any time. It is updated in the scheduler anytime a thread is added or removed from the readyList(ReadyToRun and FindNextToRun). Whenever a user process pagefaults, it sends whatever the current value of numReadyProcs is to the server in the migrateFlag field in the AckHeader. From this point on the server handles the rest of automatic load balancing. The server has a float array, clientLoad, with a spot for each individual client's load(Max 10 clients). As the server handles readRequests from clients, it sums the value at clientLoad[client] and the recieved value by weighting the current value and new recieved value. Currently the equation is clientLoad[client] = .8 * clientLoad[client] + .2 * currentClientLoad. For the automatic load balancing aspect, inside the current timeouthandler it iterates through the clientLoad array to see if there is an imbalance among the active. Currently it finds the max and min load among the clients and if the difference of the two is greater than 4, it will fork off a thread to do a migration. After the check for an imbalance, it then goes and multiplies all active clientLoad values by .8. This is done for a variety of reasons. First, the main issue with passing the load values through the page fault handling system is if there are no running user threads on a system, it will still have it's load value on the server since it is skewed toward history rather than current. This way, if a machine never pagefaults, eventually the load value will be the minimum load so it will have processes migrated to it. Another reason why this is done is if network reliability is not set to 1, because timeouts on packets sent will occur frequently, it acts as a natural deterant to the system automatically doing a migration that would prevent other machines from sending and recieving page fault message, optimizing overall system performance. Another aspect of automatic load balancing ties into the restrictions as to who can and cannot be migrated. Since it is likely that a system may become composed entirely of processes that cannot be migrated, if we send a request for a thread and the machine cannot give one up, it sends back an error case and the server immediately stops trying to migrate a process that timeout round.